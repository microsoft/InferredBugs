        public IWeightTensor TopPSampleIndice(IWeightTensor w, List<List<int>> seqs, float topP = 0.95f, float repeatPenalty = 2.0f, float distancePenalty = 10.0f)
        {
            WeightTensor m = w as WeightTensor;
            float[] weights = m.ToWeightArray();
            WeightTensor res = m_weightTensorFactory.CreateWeightTensor(new long[] { m.Rows, 1}, m_deviceId, name: $"{GetHashString(m.Name)}.Sample", graphToBind: this);

            object locker = new object();
            Random rnd = new Random(DateTime.Now.Millisecond);
            float[] indices = new float[m.Rows];
            float thresholdValue = 1.0f / (float)(m.Columns * 100000.0);

            for (int i = 0; i < m.Rows; i++)
            {
                int offset = i * m.Columns;
                List<int> seq = seqs[i];

                Dictionary<int, int> tokenId2OffsetInSeq = new Dictionary<int, int>(); // <tokenId, offsetInSeq>. The last offset of the token in the given sequence
                Dictionary<int, int> tokenId2Cnt = new Dictionary<int, int>(); // <tokenId, count> The number of token in the given sequences
                for (int j = 0; j < seq.Count; j++)
                {
                    if (tokenId2OffsetInSeq.ContainsKey(seq[j]) == false)
                    {
                        tokenId2OffsetInSeq.Add(seq[j], j);
                        tokenId2Cnt.Add(seq[j], 0);
                    }
                    else
                    {
                        tokenId2OffsetInSeq[seq[j]] = j;
                    }

                    tokenId2Cnt[seq[j]]++;
                }

                SortedDictionary<float, int> weight2tokenId = new SortedDictionary<float, int>();
                float adjustedSum = 0.0f;
                for (int j = 0; j < m.Columns; j++)
                {
                    float weight = weights[offset + j];
                    if (weight < thresholdValue || weight2tokenId.ContainsKey(weight))
                    {
                        continue;
                    }

                    //Decay weights if tokens has already been generated before
                    if (tokenId2OffsetInSeq.ContainsKey(j))
                    {
                        int offsetInSeq = tokenId2OffsetInSeq[j];
                        weight = (float)((weight * (1.0 - Math.Exp((offsetInSeq + 1 - seq.Count) / distancePenalty))) / Math.Pow(repeatPenalty, tokenId2Cnt[j]));
                    }

                    if (weight < thresholdValue || weight2tokenId.ContainsKey(weight))
                    {
                        continue;
                    }

                    adjustedSum += weight;
                    weight2tokenId.Add(weight, j);

                }


                if (topP == 0.0f)
                {
                    if (weight2tokenId.Count > 0)
                    {
                        indices[i] = weight2tokenId.Last().Value;
                    }
                }
                else
                {

                    float acc = 0.0f;
                    float seed = 0.0f;
                    lock (locker)
                    {
                        seed = (float)rnd.NextDouble() * topP * adjustedSum;
                    }

                    foreach (var pair in weight2tokenId.Reverse())
                    {
                        acc += pair.Key;

                        if (acc >= seed)
                        {
                            indices[i] = pair.Value;
                            break;
                        }
                    }
                }
            }

            res.SetWeightArray(indices);


            if (m_needsBackprop)
            {
                throw new NotSupportedException($"TopPSampleIndice operation doesn't support back propagation.");
            }


            return res;

        }