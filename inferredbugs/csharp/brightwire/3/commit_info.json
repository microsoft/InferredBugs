{
    "hash": "48e6b7f42f4bb19a53a12a962478c3e84e46eaa1",
    "message": "increased layer size and depth",
    "file_num_lines": 88,
    "diff_parsed": {
        "added": [
            [
                1,
                "\ufeffusing System;"
            ],
            [
                2,
                "using BrightWire.ExecutionGraph;"
            ],
            [
                35,
                "                        return SCALE * ALPHA * BoundMath.Exp(x);"
            ],
            [
                50,
                "                    return SCALE * (ALPHA * BoundMath.Exp(x) - ALPHA);"
            ],
            [
                58,
                "            using (var lap = BrightWireProvider.CreateLinearAlgebra()) {"
            ],
            [
                79,
                "                const float TRAINING_RATE = 0.1f;"
            ],
            [
                82,
                "\t            const int LAYER_SIZE = 32;"
            ],
            [
                83,
                ""
            ],
            [
                84,
                "\t            Func<INode> activation = () => new SeluActivation();"
            ],
            [
                85,
                "\t            //Func<INode> activation = () => graph.ReluActivation();"
            ],
            [
                86,
                ""
            ],
            [
                88,
                "\t\t\t\tgraph.Connect(engine)"
            ],
            [
                89,
                "\t\t\t\t    .AddFeedForward(LAYER_SIZE)"
            ],
            [
                90,
                "\t\t\t\t    .AddBatchNormalisation()"
            ],
            [
                91,
                "\t\t\t\t    .Add(activation())"
            ],
            [
                92,
                "\t\t\t\t    .AddFeedForward(LAYER_SIZE)"
            ],
            [
                93,
                "\t\t\t\t    .AddBatchNormalisation()"
            ],
            [
                94,
                "\t\t\t\t\t.Add(activation())"
            ],
            [
                95,
                "\t\t\t\t    .AddFeedForward(LAYER_SIZE)"
            ],
            [
                96,
                "\t\t\t\t    .AddBatchNormalisation()"
            ],
            [
                97,
                "\t\t\t\t    .Add(activation())"
            ],
            [
                98,
                "\t\t\t\t\t.AddFeedForward(LAYER_SIZE)"
            ],
            [
                99,
                "\t\t\t\t\t.AddBatchNormalisation()"
            ],
            [
                100,
                "\t\t\t\t\t.Add(activation())"
            ],
            [
                101,
                "\t\t\t\t\t.AddFeedForward(LAYER_SIZE)"
            ],
            [
                102,
                "\t\t\t\t\t.AddBatchNormalisation()"
            ],
            [
                103,
                "\t\t\t\t\t.Add(activation())"
            ],
            [
                104,
                "\t\t\t\t\t.AddFeedForward(LAYER_SIZE)"
            ],
            [
                105,
                "\t\t\t\t\t.AddBatchNormalisation()"
            ],
            [
                106,
                "\t\t\t\t\t.Add(activation())"
            ],
            [
                107,
                "\t\t\t\t    .AddFeedForward(trainingData.OutputSize)"
            ],
            [
                108,
                "\t\t\t\t    .Add(graph.SoftMaxActivation())"
            ],
            [
                109,
                "\t\t\t\t    .AddBackpropagation(errorMetric)"
            ],
            [
                110,
                "\t\t\t\t;"
            ],
            [
                112,
                "                const int TRAINING_ITERATIONS = 200;"
            ],
            [
                113,
                "                engine.Train(TRAINING_ITERATIONS, testData, errorMetric);"
            ]
        ],
        "deleted": [
            [
                1,
                "\ufeffusing BrightWire.ExecutionGraph;"
            ],
            [
                34,
                "                        else"
            ],
            [
                35,
                "                            return SCALE * ALPHA * BoundMath.Exp(x);"
            ],
            [
                50,
                "                    else"
            ],
            [
                51,
                "                        return SCALE * (ALPHA * BoundMath.Exp(x) - ALPHA);"
            ],
            [
                59,
                "            using (var lap = BrightWireGpuProvider.CreateLinearAlgebra()) {"
            ],
            [
                80,
                "                const float TRAINING_RATE = 0.01f;"
            ],
            [
                84,
                "                graph.Connect(engine)"
            ],
            [
                85,
                "                    .AddFeedForward(outputSize: 16)"
            ],
            [
                86,
                "\t                .AddBatchNormalisation()"
            ],
            [
                87,
                "                    .Add(new SeluActivation())"
            ],
            [
                88,
                "                    .AddFeedForward(trainingData.OutputSize)"
            ],
            [
                89,
                "                    .Add(graph.SoftMaxActivation())"
            ],
            [
                90,
                "                    .AddBackpropagation(errorMetric)"
            ],
            [
                91,
                "                ;"
            ],
            [
                93,
                "                // train the network, but only run the test set every 50 iterations"
            ],
            [
                94,
                "                const int TRAINING_ITERATIONS = 1500;"
            ],
            [
                95,
                "                engine.Train(TRAINING_ITERATIONS, testData, errorMetric, null);"
            ]
        ]
    },
    "num_lines_added": 36,
    "num_lines_removed": 18
}