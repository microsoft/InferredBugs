{"hash": "3fead19df7f28afb355062e48818609692d25627", "message": "Fix to prevent the onNext event going to stale subscription when restart happens in poller (#606)\n\n* Fix to prevent the onNext event going to stale subscription when restart happens in poller\r\n\r\n* Isolating session variables into a new class. Replacing thread control shifting logic for publishing with monitor based control\r\n\r\n* Refactoring based on review comments\r\n\r\n* Addressing review comments on unit test cases", "file_num_lines": 397, "diff_parsed": {"added": [[29, "import lombok.AccessLevel;"], [30, "import lombok.Getter;"], [31, "import lombok.Setter;"], [75, " * to the Subscriber (ShardConsumer in KCL)."], [95, "    @VisibleForTesting @Getter"], [96, "    private final PublisherSession publisherSession;"], [101, ""], [102, "    @Data"], [103, "    @Accessors(fluent = true)"], [104, "    static final class PublisherSession {"], [105, "        private final AtomicLong requestedResponses = new AtomicLong(0);"], [106, "        @VisibleForTesting @Getter"], [107, "        private final LinkedBlockingQueue<PrefetchRecordsRetrieved> prefetchRecordsQueue;"], [108, "        private final PrefetchCounters prefetchCounters;"], [109, "        private final KinesisDataFetcher dataFetcher;"], [110, "        private InitialPositionInStreamExtended initialPositionInStreamExtended;"], [111, "        private String highestSequenceNumber;"], [112, ""], [113, "        // Initialize the session on publisher start."], [114, "        void init(ExtendedSequenceNumber extendedSequenceNumber,"], [115, "                InitialPositionInStreamExtended initialPositionInStreamExtended) {"], [116, "            this.initialPositionInStreamExtended = initialPositionInStreamExtended;"], [117, "            this.highestSequenceNumber = extendedSequenceNumber.sequenceNumber();"], [118, "            this.dataFetcher.initialize(extendedSequenceNumber, initialPositionInStreamExtended);"], [119, "        }"], [120, ""], [121, "        // Reset the session when publisher restarts."], [122, "        void reset(PrefetchRecordsRetrieved prefetchRecordsRetrieved) {"], [123, "            // Reset the demand from ShardConsumer, to prevent this publisher from delivering events to stale RX-Java"], [124, "            // Subscriber. Publishing will be unblocked when the demand is communicated by the new Rx-Java subscriber."], [125, "            requestedResponses.set(0);"], [126, "            // Clear the queue, so that the publisher repopulates the queue based on sequence number from subscriber."], [127, "            prefetchRecordsQueue.clear();"], [128, "            prefetchCounters.reset();"], [129, "            highestSequenceNumber = prefetchRecordsRetrieved.lastBatchSequenceNumber();"], [130, "            dataFetcher.resetIterator(prefetchRecordsRetrieved.shardIterator(), highestSequenceNumber,"], [131, "                    initialPositionInStreamExtended);"], [132, "        }"], [133, ""], [134, "        // Handle records delivery ack and execute nextEventDispatchAction."], [135, "        // This method is not thread-safe and needs to be called after acquiring a monitor."], [136, "        void handleRecordsDeliveryAck(RecordsDeliveryAck recordsDeliveryAck, String shardId, Runnable nextEventDispatchAction) {"], [137, "            final PrefetchRecordsRetrieved recordsToCheck = peekNextRecord();"], [138, "            // Verify if the ack matches the head of the queue and evict it."], [139, "            if (recordsToCheck != null && recordsToCheck.batchUniqueIdentifier().equals(recordsDeliveryAck.batchUniqueIdentifier())) {"], [140, "                evictPublishedRecordAndUpdateDemand(shardId);"], [141, "                nextEventDispatchAction.run();"], [142, "            } else {"], [143, "                // Log and ignore any other ack received. As long as an ack is received for head of the queue"], [144, "                // we are good. Any stale or future ack received can be ignored, though the latter is not feasible"], [145, "                // to happen."], [146, "                final BatchUniqueIdentifier peekedBatchUniqueIdentifier ="], [147, "                        recordsToCheck == null ? null : recordsToCheck.batchUniqueIdentifier();"], [148, "                log.info(\"{} :  Received a stale notification with id {} instead of expected id {} at {}. Will ignore.\","], [149, "                        shardId, recordsDeliveryAck.batchUniqueIdentifier(), peekedBatchUniqueIdentifier, Instant.now());"], [150, "            }"], [151, "        }"], [152, ""], [153, "        // Evict the published record from the prefetch queue."], [154, "        // This method is not thread-safe and needs to be called after acquiring a monitor."], [155, "        @VisibleForTesting"], [156, "        RecordsRetrieved evictPublishedRecordAndUpdateDemand(String shardId) {"], [157, "            final PrefetchRecordsRetrieved result = prefetchRecordsQueue.poll();"], [158, "            if (result != null) {"], [159, "                updateDemandTrackersOnPublish(result);"], [160, "            } else {"], [161, "                log.info("], [162, "                        \"{}: No record batch found while evicting from the prefetch queue. This indicates the prefetch buffer\""], [163, "                                + \"was reset.\", shardId);"], [164, "            }"], [165, "            return result;"], [166, "        }"], [167, ""], [168, "        boolean hasDemandToPublish() {"], [169, "            return requestedResponses.get() > 0;"], [170, "        }"], [171, ""], [172, "        PrefetchRecordsRetrieved peekNextRecord() {"], [173, "            return prefetchRecordsQueue.peek();"], [174, "        }"], [175, ""], [176, "        boolean offerRecords(PrefetchRecordsRetrieved recordsRetrieved, long idleMillisBetweenCalls) throws InterruptedException {"], [177, "            return prefetchRecordsQueue.offer(recordsRetrieved, idleMillisBetweenCalls, TimeUnit.MILLISECONDS);"], [178, "        }"], [179, ""], [180, "        private void updateDemandTrackersOnPublish(PrefetchRecordsRetrieved result) {"], [181, "            prefetchCounters.removed(result.processRecordsInput);"], [182, "            requestedResponses.decrementAndGet();"], [183, "        }"], [184, ""], [185, "    }"], [215, "        this.publisherSession = new PublisherSession(new LinkedBlockingQueue<>(this.maxPendingProcessRecordsInput),"], [216, "                new PrefetchCounters(), this.getRecordsRetrievalStrategy.getDataFetcher());"], [232, "        publisherSession.init(extendedSequenceNumber, initialPositionInStreamExtended);"], [251, "    private PrefetchRecordsRetrieved peekNextResult() {"], [253, "        return publisherSession.peekNextRecord();"], [271, "            publisherSession.reset((PrefetchRecordsRetrieved)recordsRetrieved);"], [284, "                publisherSession.requestedResponses().addAndGet(n);"], [285, "                drainQueueForRequests();"], [290, "                // When the subscription is cancelled, the demand is set to 0, to prevent further"], [291, "                // records from being dispatched to the consumer/subscriber. The publisher session state will be"], [292, "                // reset when restartFrom(*) is called by the consumer/subscriber."], [293, "                publisherSession.requestedResponses().set(0);"], [300, "        publisherSession.handleRecordsDeliveryAck(recordsDeliveryAck, shardId, () -> drainQueueForRequests());"], [308, "        while (!publisherSession.offerRecords(recordsRetrieved, idleMillisBetweenCalls)) {"], [321, "        publisherSession.prefetchCounters().added(recordsRetrieved.processRecordsInput);"], [327, "    @VisibleForTesting"], [328, "    synchronized void drainQueueForRequests() {"], [329, "        final PrefetchRecordsRetrieved recordsToDeliver = peekNextResult();"], [332, "        if (publisherSession.hasDemandToPublish() && canDispatchRecord(recordsToDeliver)) {"], [333, "            subscriber.onNext(recordsToDeliver.prepareForPublish());"], [334, "            recordsToDeliver.dispatched();"], [339, "    // This method is thread-safe and informs the caller on whether this record is eligible to be dispatched."], [340, "    // If this record was already dispatched earlier, then this method would return false."], [341, "    private static boolean canDispatchRecord(PrefetchRecordsRetrieved recordsToDeliver) {"], [342, "        return recordsToDeliver != null && !recordsToDeliver.isDispatched();"], [343, "    }"], [344, ""], [353, "        @Accessors() @Setter(AccessLevel.NONE) boolean dispatched = false;"], [365, "        // Indicates if this record batch was already dispatched for delivery."], [366, "        void dispatched() { dispatched = true; }"], [367, ""], [376, ""], [380, "        String result = publisherSession.highestSequenceNumber();"], [419, "            if (publisherSession.prefetchCounters().shouldGetNewRecords()) {"], [435, "                            calculateHighestSequenceNumber(processRecordsInput), getRecordsResult.nextShardIterator(),"], [437, "                    publisherSession.highestSequenceNumber(recordsRetrieved.lastBatchSequenceNumber);"], [439, "                    drainQueueForRequests();"], [452, "                    publisherSession.dataFetcher().restartIterator();"], [468, "                    publisherSession.prefetchCounters().waitForConsumer();"], [537, "            return String.format(\"{ Requests: %d, Records: %d, Bytes: %d }\", publisherSession.prefetchRecordsQueue().size(), size,"]], "deleted": [[25, "import java.util.concurrent.atomic.AtomicBoolean;"], [73, " * to the Subscriber (ShardConsumer in KCL). The publisher/demand-notifier thread gains the control to drain only when"], [74, " * there is no pending event in the prefetch queue waiting for the ack. Otherwise, it will be the ack-notifier thread"], [75, " * which will drain an event on the receipt of an ack."], [76, " *"], [82, "    @VisibleForTesting"], [83, "    LinkedBlockingQueue<PrefetchRecordsRetrieved> getRecordsResultQueue;"], [94, "    private PrefetchCounters prefetchCounters;"], [97, "    private final KinesisDataFetcher dataFetcher;"], [99, ""], [101, "    private final AtomicLong requestedResponses = new AtomicLong(0);"], [102, ""], [103, "    private String highestSequenceNumber;"], [104, "    private InitialPositionInStreamExtended initialPositionInStreamExtended;"], [105, ""], [110, "    // This flag controls who should drain the next request in the prefetch queue."], [111, "    // When set to false, the publisher and demand-notifier thread would have the control."], [112, "    // When set to true, the event-notifier thread would have the control."], [113, "    private AtomicBoolean shouldDrainEventOnlyOnAck = new AtomicBoolean(false);"], [143, "        this.getRecordsResultQueue = new LinkedBlockingQueue<>(this.maxPendingProcessRecordsInput);"], [144, "        this.prefetchCounters = new PrefetchCounters();"], [151, "        this.dataFetcher = this.getRecordsRetrievalStrategy.getDataFetcher();"], [161, "        this.initialPositionInStreamExtended = initialPositionInStreamExtended;"], [162, "        highestSequenceNumber = extendedSequenceNumber.sequenceNumber();"], [163, "        dataFetcher.initialize(extendedSequenceNumber, initialPositionInStreamExtended);"], [182, "    private RecordsRetrieved peekNextResult() {"], [183, "        throwOnIllegalState();"], [184, "        final PrefetchRecordsRetrieved result = getRecordsResultQueue.peek();"], [185, "        return result == null ? result : result.prepareForPublish();"], [186, "    }"], [187, ""], [188, "    @VisibleForTesting"], [189, "    RecordsRetrieved pollNextResultAndUpdatePrefetchCounters() {"], [191, "        final PrefetchRecordsRetrieved result = getRecordsResultQueue.poll();"], [192, "        if (result != null) {"], [193, "            prefetchCounters.removed(result.processRecordsInput);"], [194, "            requestedResponses.decrementAndGet();"], [195, "        } else {"], [196, "            log.info("], [197, "                    \"{}: No record batch found while evicting from the prefetch queue. This indicates the prefetch buffer\""], [198, "                            + \"was reset.\", shardId);"], [199, "        }"], [200, "        return result;"], [216, "        PrefetchRecordsRetrieved prefetchRecordsRetrieved = (PrefetchRecordsRetrieved) recordsRetrieved;"], [219, "            getRecordsResultQueue.clear();"], [220, ""], [221, "            // Give the drain control to publisher/demand-notifier thread."], [222, "            log.debug(\"{} : Publisher thread takes over the draining control. Queue Size : {}, Demand : {}\", shardId,"], [223, "                    getRecordsResultQueue.size(), requestedResponses.get());"], [224, "            shouldDrainEventOnlyOnAck.set(false);"], [225, ""], [226, "            prefetchCounters.reset();"], [227, ""], [228, "            highestSequenceNumber = prefetchRecordsRetrieved.lastBatchSequenceNumber();"], [229, "            dataFetcher.resetIterator(prefetchRecordsRetrieved.shardIterator(), highestSequenceNumber,"], [230, "                    initialPositionInStreamExtended);"], [243, "                requestedResponses.addAndGet(n);"], [244, "                drainQueueForRequestsIfAllowed();"], [249, "                requestedResponses.set(0);"], [256, "        final RecordsRetrieved recordsToCheck = peekNextResult();"], [257, "        // Verify if the ack matches the head of the queue and evict it."], [258, "        if (recordsToCheck != null && recordsToCheck.batchUniqueIdentifier()"], [259, "                .equals(recordsDeliveryAck.batchUniqueIdentifier())) {"], [260, "            pollNextResultAndUpdatePrefetchCounters();"], [261, "            // Upon evicting, check if queue is empty. if yes, then give the drain control back to publisher thread."], [262, "            if (getRecordsResultQueue.isEmpty()) {"], [263, "                log.debug(\"{} : Publisher thread takes over the draining control. Queue Size : {}, Demand : {}\","], [264, "                        shardId, getRecordsResultQueue.size(), requestedResponses.get());"], [265, "                shouldDrainEventOnlyOnAck.set(false);"], [266, "            } else {"], [267, "                // Else attempt to drain the queue."], [268, "                drainQueueForRequests();"], [269, "            }"], [270, "        } else {"], [271, "            // Log and ignore any other ack received. As long as an ack is received for head of the queue"], [272, "            // we are good. Any stale or future ack received can be ignored, though the latter is not feasible"], [273, "            // to happen."], [274, "            final BatchUniqueIdentifier peekedBatchUniqueIdentifier ="], [275, "                    recordsToCheck == null ? null : recordsToCheck.batchUniqueIdentifier();"], [276, "            log.info(\"{} :  Received a stale notification with id {} instead of expected id {} at {}. Will ignore.\","], [277, "                    shardId, recordsDeliveryAck.batchUniqueIdentifier(), peekedBatchUniqueIdentifier, Instant.now());"], [278, "        }"], [286, "        while (!getRecordsResultQueue.offer(recordsRetrieved, idleMillisBetweenCalls, TimeUnit.MILLISECONDS)) {"], [299, "        prefetchCounters.added(recordsRetrieved.processRecordsInput);"], [300, "    }"], [301, ""], [302, "    /**"], [303, "     * Method that will be called by the 'publisher thread' and the 'demand notifying thread',"], [304, "     * to drain the events if the 'event notifying thread' do not have the control."], [305, "     */"], [306, "    private synchronized void drainQueueForRequestsIfAllowed() {"], [307, "        if (!shouldDrainEventOnlyOnAck.get()) {"], [308, "            drainQueueForRequests();"], [309, "        }"], [315, "    private synchronized void drainQueueForRequests() {"], [316, "        final RecordsRetrieved recordsToDeliver = peekNextResult();"], [319, "        if (requestedResponses.get() > 0 && recordsToDeliver != null) {"], [321, "            subscriber.onNext(recordsToDeliver);"], [322, "            if (!shouldDrainEventOnlyOnAck.get()) {"], [323, "                log.debug(\"{} : Notifier thread takes over the draining control. Queue Size : {}, Demand : {}\", shardId,"], [324, "                        getRecordsResultQueue.size(), requestedResponses.get());"], [325, "                shouldDrainEventOnlyOnAck.set(true);"], [326, "            }"], [327, "        } else {"], [328, "            // Since we haven't scheduled the event delivery, give the drain control back to publisher/demand-notifier"], [329, "            // thread."], [330, "            if (shouldDrainEventOnlyOnAck.get()) {"], [331, "                log.debug(\"{} : Publisher thread takes over the draining control. Queue Size : {}, Demand : {}\","], [332, "                        shardId, getRecordsResultQueue.size(), requestedResponses.get());"], [333, "                shouldDrainEventOnlyOnAck.set(false);"], [334, "            }"], [368, "        String result = this.highestSequenceNumber;"], [407, "            if (prefetchCounters.shouldGetNewRecords()) {"], [422, "                    highestSequenceNumber = calculateHighestSequenceNumber(processRecordsInput);"], [424, "                            highestSequenceNumber, getRecordsResult.nextShardIterator(),"], [426, "                    highestSequenceNumber = recordsRetrieved.lastBatchSequenceNumber;"], [428, "                    drainQueueForRequestsIfAllowed();"], [441, "                    dataFetcher.restartIterator();"], [457, "                    prefetchCounters.waitForConsumer();"], [526, "            return String.format(\"{ Requests: %d, Records: %d, Bytes: %d }\", getRecordsResultQueue.size(), size,"]]}, "num_lines_added": 131, "num_lines_removed": 120}