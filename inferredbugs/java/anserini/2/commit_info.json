{"hash": "90ac8324d3b1681b668275fd9a76b9459496f07d", "message": "Cleaned up commandline args; realized that RM3 implementation that worked was based on BM25, which is janky.", "file_num_lines": 109, "diff_parsed": {"added": [[3, "import io.anserini.rerank.IdentityReranker;"], [10, "import java.io.File;"], [11, "import java.io.FileOutputStream;"], [18, "import org.apache.logging.log4j.LogManager;"], [19, "import org.apache.logging.log4j.Logger;"], [29, "import org.apache.lucene.search.similarities.LMDirichletSimilarity;"], [30, "import org.apache.lucene.store.Directory;"], [33, "import org.kohsuke.args4j.CmdLineException;"], [34, "import org.kohsuke.args4j.CmdLineParser;"], [35, "import org.kohsuke.args4j.OptionHandlerFilter;"], [36, "import org.kohsuke.args4j.ParserProperties;"], [37, ""], [38, "public class SearchGov2 {"], [39, "  private static final Logger LOG = LogManager.getLogger(SearchGov2.class);"], [42, "    long curTime = System.nanoTime();"], [43, "    SearchArgs searchArgs = new SearchArgs();"], [44, "    CmdLineParser parser = new CmdLineParser(searchArgs, ParserProperties.defaults().withUsageWidth(90));"], [45, ""], [46, "    try {"], [47, "      parser.parseArgument(args);"], [48, "    } catch (CmdLineException e) {"], [49, "      System.err.println(e.getMessage());"], [50, "      parser.printUsage(System.err);"], [51, "      System.err.println(\"Example: SearchGov2\" + parser.printExample(OptionHandlerFilter.REQUIRED));"], [52, "      return;"], [53, "    }"], [55, "    Path topicsFile = Paths.get(searchArgs.topics);"], [56, ""], [57, "    LOG.info(\"Reading index at \" + searchArgs.index);"], [58, "    Directory dir;"], [59, "    if (searchArgs.inmem) {"], [60, "      LOG.info(\"Using MMapDirectory with preload\");"], [61, "      dir = new MMapDirectory(Paths.get(searchArgs.index));"], [62, "      ((MMapDirectory) dir).setPreload(true);"], [63, "    } else {"], [64, "      LOG.info(\"Using default FSDirectory\");"], [65, "      dir = FSDirectory.open(Paths.get(searchArgs.index));"], [71, "    if (searchArgs.ql) {"], [72, "      LOG.info(\"Using QL scoring model\");"], [73, "      searcher.setSimilarity(new LMDirichletSimilarity(2500.0f));"], [74, "    } else if (searchArgs.rm3) {"], [75, "      LOG.info(\"Using RM3 query expansion\");"], [76, "      searcher.setSimilarity(new BM25Similarity(0.9f, 0.4f));"], [77, "    } else if (searchArgs.bm25) {"], [78, "      LOG.info(\"Using BM25 scoring model\");"], [79, "      searcher.setSimilarity(new BM25Similarity(0.9f, 0.4f));"], [80, "    } else {"], [81, "      LOG.error(\"Error: Must specify scoring model!\");"], [82, "      System.exit(-1);"], [83, "    }"], [90, "    PrintStream out = new PrintStream(new FileOutputStream(new File(searchArgs.output)));"], [91, "    LOG.info(\"Writing output to \" + searchArgs.output);"], [93, "    LOG.info(\"Initialized complete! (elapsed time = \" + (System.nanoTime()-curTime)/1000000 + \"ms)\");"], [94, "    long totalTime = 0;"], [96, "      long curQueryTime = System.nanoTime();"], [103, "      if (searchArgs.rm3) {"], [104, "        cascade.add(new Rm3Reranker(new EnglishAnalyzer(), \"body\"));"], [105, "      } else {"], [106, "        cascade.add(new IdentityReranker());"], [107, "      }"], [116, "      long qtime = (System.nanoTime()-curQueryTime)/1000000;"], [117, "      LOG.info(\"Query \" + qq.getQueryID() + \" (elapsed time = \" + qtime + \"ms)\");"], [118, "      totalTime += qtime;"], [121, "    LOG.info(\"All queries completed!\");"], [122, "    LOG.info(\"Total elapsed time = \" + totalTime + \"ms\");"], [123, "    LOG.info(\"Average query latency = \" + (totalTime/qqs.length) + \"ms\");"], [124, ""]], "deleted": [[9, "import java.io.OutputStreamWriter;"], [11, "import java.io.PrintWriter;"], [12, "import java.nio.charset.Charset;"], [17, "import java.util.HashSet;"], [18, "import java.util.Set;"], [22, "import org.apache.lucene.benchmark.quality.QualityQueryParser;"], [23, "import org.apache.lucene.benchmark.quality.trec.QueryDriver;"], [25, "import org.apache.lucene.benchmark.quality.utils.SubmissionReport;"], [28, "import org.apache.lucene.queryparser.classic.ParseException;"], [29, "import org.apache.lucene.queryparser.classic.QueryParser;"], [30, "import org.apache.lucene.queryparser.classic.QueryParserBase;"], [31, "import org.apache.lucene.search.BooleanClause;"], [32, "import org.apache.lucene.search.BooleanQuery;"], [40, "public class SearchGov2 extends QueryDriver {"], [43, "    if (args.length < 4 || args.length > 5) {"], [44, "      System.err.println(\"Usage: QueryDriver <topicsFile> <qrelsFile> <submissionFile> <indexDir> [querySpec]\");"], [45, "      System.err.println(\"topicsFile: input file containing queries\");"], [46, "      System.err.println(\"qrelsFile: input file containing relevance judgements\");"], [47, "      System.err.println(\"submissionFile: output submission file for trec_eval\");"], [48, "      System.err.println(\"indexDir: index directory\");"], [49, "      System.err.println(\"querySpec: string composed of fields to use in query consisting of T=title,D=description,N=narrative:\");"], [50, "      System.err.println(\"\\texample: TD (query on Title + Description). The default is T (title only)\");"], [51, "      System.exit(1);"], [54, "    Path topicsFile = Paths.get(args[0]);"], [55, "    Path qrelsFile = Paths.get(args[1]);"], [56, "    Path submissionFile = Paths.get(args[2]);"], [57, "    SubmissionReport submitLog = new SubmissionReport(new PrintWriter(Files.newBufferedWriter(submissionFile, StandardCharsets.UTF_8)), \"lucene\");"], [58, "    MMapDirectory dir = new MMapDirectory(Paths.get(args[3]));"], [59, "    dir.setPreload(true);"], [60, "    String fieldSpec = args.length == 5 ? args[4] : \"T\"; // default to Title-only if not specified."], [64, "    searcher.setSimilarity(new BM25Similarity(0.9f, 0.4f));"], [65, "    //searcher.setSimilarity(new LMDirichletSimilarity(2500.0f));"], [68, "    String docNameField = \"docid\";"], [70, "    PrintWriter logger = new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()), true);"], [71, ""], [72, "    // use trec utilities to read trec topics into quality queries"], [76, "    // prepare judge, with trec utilities that read from a QRels file"], [77, "    //Judge judge = new TrecJudge(Files.newBufferedReader(qrelsFile, StandardCharsets.UTF_8));"], [78, ""], [79, "    // validate topics & judgments match each other"], [80, "    //judge.validateData(qqs, logger);"], [81, ""], [82, "    Set<String> fieldSet = new HashSet<>();"], [83, "    if (fieldSpec.indexOf('T') >= 0) fieldSet.add(\"title\");"], [84, "    if (fieldSpec.indexOf('D') >= 0) fieldSet.add(\"description\");"], [85, "    if (fieldSpec.indexOf('N') >= 0) fieldSet.add(\"narrative\");"], [86, ""], [87, "    // set the parsing of quality queries into Lucene queries."], [88, "    QualityQueryParser qqParser = new EnglishQQParser(fieldSet.toArray(new String[0]), \"body\");"], [89, ""], [90, "    PrintStream out = new PrintStream(System.out, true, \"UTF-8\");"], [93, "      //System.out.println(qq.getValue(\"title\"));"], [94, ""], [96, "      //System.out.println(query);"], [102, "      cascade.add(new Rm3Reranker(new EnglishAnalyzer(), \"body\"));"], [113, "//    // run the benchmark"], [114, "//    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);"], [115, "//    qrun.setMaxResults(maxResults);"], [116, "//    QualityStats stats[] = qrun.execute(judge, submitLog, logger);"], [117, "//"], [118, "//    // print an avarage sum of the results"], [119, "//    QualityStats avg = QualityStats.average(stats);"], [120, "//    avg.log(\"SUMMARY\", 2, logger, \"  \");"], [121, ""], [127, ""], [128, "class EnglishQQParser implements QualityQueryParser {"], [129, ""], [130, "  private String qqNames[];"], [131, "  private String indexField;"], [132, "  ThreadLocal<QueryParser> queryParser = new ThreadLocal<>();"], [133, ""], [134, "  /**"], [135, "   * Constructor of a simple qq parser."], [136, "   * @param qqNames name-value pairs of quality query to use for creating the query"], [137, "   * @param indexField corresponding index field"], [138, "   */"], [139, "  public EnglishQQParser(String qqNames[], String indexField) {"], [140, "    this.qqNames = qqNames;"], [141, "    this.indexField = indexField;"], [142, "  }"], [143, ""], [144, "  /**"], [145, "   * Constructor of a simple qq parser."], [146, "   * @param qqName name-value pair of quality query to use for creating the query"], [147, "   * @param indexField corresponding index field"], [148, "   */"], [149, "  public EnglishQQParser(String qqName, String indexField) {"], [150, "    this(new String[] { qqName }, indexField);"], [151, "  }"], [152, ""], [153, "  /* (non-Javadoc)"], [154, "   * @see org.apache.lucene.benchmark.quality.QualityQueryParser#parse(org.apache.lucene.benchmark.quality.QualityQuery)"], [155, "   */"], [156, "  @Override"], [157, "  public Query parse(QualityQuery qq) throws ParseException {"], [158, "    QueryParser qp = queryParser.get();"], [159, "    if (qp==null) {"], [160, "      qp = new QueryParser(indexField, new EnglishAnalyzer());"], [161, "      queryParser.set(qp);"], [162, "    }"], [163, "    BooleanQuery bq = new BooleanQuery();"], [164, "    for (int i = 0; i < qqNames.length; i++)"], [165, "      bq.add(qp.parse(QueryParserBase.escape(qq.getValue(qqNames[i]))), BooleanClause.Occur.SHOULD);"], [166, ""], [167, "    return bq;"], [168, "  }"], [169, ""], [170, "}"], [171, ""]]}, "num_lines_added": 67, "num_lines_removed": 109}