{"hash": "990c63426571233d3370d07634db912c1e4fbd82", "message": "Part of the TokenPatternExtractor", "file_num_lines": 135, "diff_parsed": {"added": [[3, "import org.jetbrains.annotations.Nullable;"], [4, "import org.panda_lang.panda.framework.design.interpreter.token.TokenRepresentation;"], [8, "import org.panda_lang.panda.framework.language.interpreter.pattern.lexical.elements.LexicalPatternUnit;"], [9, "import org.panda_lang.panda.framework.language.interpreter.token.PandaTokenizedSource;"], [26, "        return extract(pattern.getPatternContent(), new TokenDistributor(source));"], [29, "    protected TokenExtractorResult extract(LexicalPatternElement element, TokenDistributor distributor) {"], [30, "        if (!distributor.hasNext()) {"], [35, "            return new TokenExtractorResult(element.toUnit().getValue().equals(distributor.next().getTokenValue()));"], [39, "            return new TokenExtractorResult();"], [45, "            return this.matchVariant(node, distributor);"], [49, "        TokenizedSource[] dynamics = this.matchUnits(elements, distributor);"], [58, "    private @Nullable TokenizedSource[] matchUnits(List<LexicalPatternElement> elements, TokenDistributor distributor) {"], [60, ""], [61, "        for (int i = 0; i < elements.size(); i++) {"], [62, "            LexicalPatternElement element = elements.get(i);"], [63, ""], [64, "            if (!element.isUnit()) {"], [65, "                continue;"], [66, "            }"], [67, ""], [68, "            LexicalPatternUnit unit = element.toUnit();"], [69, "            boolean found = false;"], [70, "            int dynamic = 0;"], [71, ""], [72, "            for (TokenRepresentation representation : distributor) {"], [73, "                if (representation.getTokenValue().equals(unit.getValue())) {"], [74, "                    found = true;"], [75, "                    break;"], [76, "                }"], [77, ""], [78, "                dynamic++;"], [79, "            }"], [80, ""], [81, "            if (!found && unit.isOptional()) {"], [82, "                continue;"], [83, "            }"], [84, ""], [85, "            if (!found && (distributor.getIndex() + dynamic != distributor.length()) && !unit.isOptional()) {"], [86, "                return null;"], [87, "            }"], [88, ""], [89, "            if (dynamic == 0) {"], [90, "                distributor.next();"], [91, "                continue;"], [92, "            }"], [93, ""], [94, "            if ((found) || (distributor.getIndex() + dynamic == distributor.length() && unit.isOptional())) {"], [95, "                dynamics[getLastDynamicIndex(dynamics)] = new PandaTokenizedSource(distributor.next(dynamic));"], [96, "                distributor.next();"], [97, "            }"], [98, "        }"], [99, ""], [100, "        return dynamics;"], [124, "            TokenDistributor content = new TokenDistributor(nodeContent);"], [125, "            TokenExtractorResult nodeElementResult = this.extract(nodeElement, content);"], [131, "            if (content.hasNext()) {"], [132, "                int nextIndex = i + 1;"], [133, ""], [134, "                if (nextIndex >= dynamics.length || dynamics[nextIndex] != null) {"], [135, "                    return new TokenExtractorResult();"], [136, "                }"], [137, ""], [138, "                dynamics[nextIndex] = new PandaTokenizedSource(content.next(content.length() - content.getIndex()));"], [139, "            }"], [140, ""], [147, "                return new TokenExtractorResult();"], [154, "    private TokenExtractorResult matchVariant(LexicalPatternNode variantNode, TokenDistributor reader) {"], [170, "    private int getLastDynamicIndex(TokenizedSource[] dynamics) {"], [171, "        for (int i = dynamics.length - 1; i > -1; i--) {"], [172, "            if (dynamics[i] == null) {"], [173, "                continue;"], [174, "            }"], [175, ""], [176, "            return i + 1;"], [177, "        }"], [178, ""], [179, "        return 0;"], [180, "    }"], [181, ""]], "deleted": [[4, "import org.panda_lang.panda.framework.design.interpreter.token.stream.TokenReader;"], [7, "import org.panda_lang.panda.framework.language.interpreter.token.stream.PandaTokenReader;"], [24, "        return extract(pattern.getPatternContent(), new PandaTokenReader(source));"], [27, "    protected TokenExtractorResult extract(LexicalPatternElement element, TokenReader reader) {"], [28, "        if (!reader.hasNext()) {"], [33, "            return new TokenExtractorResult(element.toUnit().getValue().equals(reader.next().getTokenValue()));"], [37, "            return null;"], [43, "            return this.matchVariant(node, reader);"], [47, "        TokenizedSource[] dynamics = this.matchUnits(elements, reader);"], [56, "    private TokenizedSource[] matchUnits(List<LexicalPatternElement> elements, TokenReader reader) {"], [58, "        return null;"], [82, "            TokenExtractorResult nodeElementResult = this.extract(nodeElement, new PandaTokenReader(nodeContent));"], [94, "                return new TokenExtractorResult(false);"], [101, "    private TokenExtractorResult matchVariant(LexicalPatternNode variantNode, TokenReader reader) {"]]}, "num_lines_added": 79, "num_lines_removed": 14}