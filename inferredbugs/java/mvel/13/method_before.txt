    public CompiledExpression _compile() {
        ASTNode tk;
        ASTNode tkOp;
        ASTNode tkOp2;
        ASTNode tkLA;
        ASTNode tkLA2;
        ASTLinkedList astLinkedList = new ASTLinkedList();

        boolean firstLA;

        pCtx = getParserContext();

        try {
            if (verifying) {
//                inputs = new LinkedHashSet<String>();
//                locals = new LinkedHashSet<String>();

                getParserContext().initializeTables();
            }

            fields |= ASTNode.COMPILE_IMMEDIATE;

            while ((tk = nextToken()) != null) {
                if (tk.fields == -1) {
                    astLinkedList.addTokenNode(tk);
                    continue;
                }

                returnType = tk.getEgressType();

                if (pCtx.isStrictTypeEnforcement() && tk instanceof AssignmentNode
                        && (pCtx.getInputs() == null
                        || !pCtx.getInputs().containsKey(tk.getName()))) {

                    addFatalError("untyped var not permitted in strict-mode: " + tk.getName());
                }

                if (tk instanceof Substatement) {
                    ExpressionCompiler subCompiler = new ExpressionCompiler(tk.getNameAsArray());
                    tk.setAccessor(subCompiler._compile());
//
//                    if (verifying) {
//                        inputs.addAll(subCompiler.getInputs());
//                    }
                }

                /**
                 * This kludge of code is to handle _compile-time literal reduction.  We need to avoid
                 * reducing for certain literals like, 'this', ternary and ternary else.
                 */
                if (tk.isLiteral() && tk.getLiteralValue() != LITERALS.get("this")) {
                    if ((tkOp = nextToken()) != null && tkOp.isOperator()
                            && !tkOp.isOperator(Operator.TERNARY) && !tkOp.isOperator(Operator.TERNARY_ELSE)) {

                        /**
                         * If the next token is ALSO a literal, then we have a candidate for a _compile-time
                         * reduction.
                         */
                        if ((tkLA = nextToken()) != null && tkLA.isLiteral()) {
                            stk.push(tk.getLiteralValue(), tkLA.getLiteralValue(), tkOp.getLiteralValue());

                            /**
                             * Reduce the token now.
                             */
                            reduceTrinary();

                            firstLA = true;

                            /**
                             * Now we need to check to see if this is actually a continuing reduction.
                             */
                            while ((tkOp2 = nextToken()) != null) {
                                if (!tkOp2.isOperator(tkOp.getOperator())) {
                                    /**
                                     * We can't continue any further because we are dealing with
                                     * different operators.
                                     */
                                    astLinkedList.addTokenNode(new LiteralNode(stk.pop()));
                                    astLinkedList.addTokenNode(tkOp2);
                                    break;
                                }
                                else if ((tkLA2 = nextToken()) != null
                                        && tkLA2.isLiteral()) {

                                    stk.push(tkLA2.getLiteralValue(), tkOp2.getLiteralValue());
                                    reduceTrinary();
                                    firstLA = false;
                                }
                                else {
                                    if (firstLA) {
                                        /**
                                         * There are more tokens, but we can't reduce anymore.  So
                                         * we create a reduced token for what we've got.
                                         */
                                        astLinkedList.addTokenNode(new ASTNode(ASTNode.LITERAL, stk.pop()));
                                    }
                                    else {
                                        /**
                                         * We have reduced additional tokens, but we can't reduce
                                         * anymore.
                                         */
                                        astLinkedList.addTokenNode(new ASTNode(ASTNode.LITERAL, stk.pop()), tkOp);

                                        if (tkLA2 != null) astLinkedList.addTokenNode(tkLA2);
                                    }
                                    break;
                                }
                            }

                            /**
                             * If there are no more tokens left to parse, we check to see if
                             * we've been doing any reducing, and if so we create the token
                             * now.
                             */
                            if (!stk.isEmpty())
                                astLinkedList.addTokenNode(new ASTNode(ASTNode.LITERAL, stk.pop()));

                            continue;
                        }
                        else {
                            astLinkedList.addTokenNode(verify(pCtx, tk), verify(pCtx, tkOp));
                            if (tkLA != null) astLinkedList.addTokenNode(verify(pCtx, tkLA));
                            continue;
                        }
                    }
                    else {
                        astLinkedList.addTokenNode(verify(pCtx, tk));
                        if (tkOp != null) astLinkedList.addTokenNode(verify(pCtx, tkOp));

                        continue;
                    }
                }
                astLinkedList.addTokenNode(verify(pCtx, tk));
            }

            if (verifying) {
//                for (String s : locals) {
//                    inputs.remove(s);
//                }
                pCtx.processTables();
            }

            if (pCtx.isFatalError()) {
                parserContext.remove();
                throw new CompileException("Failed to _compile: " + pCtx.getErrorList().size() + " compilation error(s)", pCtx.getErrorList());
            }
            else if (pCtx.isFatalError()) {
                parserContext.remove();
                throw new CompileException("Failed to _compile: " + pCtx.getErrorList().size() + " compilation error(s)", pCtx.getErrorList());
            }

            return new CompiledExpression(new ASTArrayList(astLinkedList), getCurrentSourceFileName());
        }
        catch (Throwable e) {
            parserContext.remove();
            if (e instanceof RuntimeException) throw (RuntimeException) e;
            else {
                throw new CompileException(e.getMessage(), e);
            }
        }

    }