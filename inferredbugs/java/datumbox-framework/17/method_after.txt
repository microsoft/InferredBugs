    private void batchGradientDescent(Dataframe trainingData, Map<List<Object>, Double> newThitas, double learningRate) {
        //NOTE! This is not the stochastic gradient descent. It is the batch gradient descent optimized for speed (despite it looks more than the stochastic). 
        //Despite the fact that the loops are inverse, the function still changes the values of Thitas at the end of the function. We use the previous thitas 
        //to estimate the costs and only at the end we update the new thitas.
        ModelParameters modelParameters = kb().getModelParameters();

        double multiplier = learningRate/modelParameters.getN();
        Map<List<Object>, Double> thitas = modelParameters.getThitas();
        Set<Object> classesSet = modelParameters.getClasses();
        
        StreamMethods.stream(trainingData.stream(), isParallelized()).forEach(r -> { 
            //mind the fact that we use the previous thitas to estimate the new ones! this is because the thitas must be updated simultaniously
            AssociativeArray classProbabilities = hypothesisFunction(r.getX(), thitas);
            for(Object theClass : classesSet) {
                
                double error;
                double score = classProbabilities.getDouble(theClass);
                if(r.getY().equals(theClass)) {
                    error = 1 - score;
                }
                else {
                    error = - score;
                }
                
                double errorMultiplier = multiplier*error;
                
                synchronized(newThitas) {
                    //update the weight of constant
                    List<Object> featureClassTuple = Arrays.<Object>asList(Dataframe.COLUMN_NAME_CONSTANT, theClass);
                    newThitas.put(featureClassTuple, newThitas.get(featureClassTuple)+errorMultiplier);

                    //update the rest of the weights
                    for(Map.Entry<Object, Object> entry : r.getX().entrySet()) {
                        Double value = TypeInference.toDouble(entry.getValue());

                        Object feature = entry.getKey();
                        featureClassTuple = Arrays.<Object>asList(feature, theClass);

                        Double thitaWeight = newThitas.get(featureClassTuple);
                        if(thitaWeight!=null) {//ensure that the feature is in the dictionary
                            newThitas.put(featureClassTuple, thitaWeight+errorMultiplier*value);
                        }
                    }
                }
            }
        });
        
    }