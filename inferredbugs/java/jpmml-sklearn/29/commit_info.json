{"hash": "94bbfadb70013744a35f5e5f8bcc5b26f66c49da", "message": "Added support for the 'Splitter' callable type", "file_num_lines": 157, "diff_parsed": {"added": [[48, "import sklearn2pmml.feature_extraction.text.Splitter;"], [143, "\t\tObject preprocessor = getPreprocessor();"], [145, "\t\tSplitter tokenizer = getTokenizer();"], [154, "\t\tif(preprocessor != null){"], [155, "\t\t\tthrow new IllegalArgumentException();"], [158, "\t\tif(stripAccents != null){"], [159, "\t\t\tthrow new IllegalArgumentException(stripAccents);"], [162, "\t\tParameterField documentField = new ParameterField(FieldName.create(\"text\"));"], [168, "\t\t\t.setWordSeparatorCharacterRE(tokenizer.getSeparatorRE())"], [196, "\tpublic Object getPreprocessor(){"], [197, "\t\treturn get(\"preprocessor\");"], [198, "\t}"], [199, ""], [204, "\tpublic Splitter getTokenizer(){"], [205, "\t\tObject tokenizer = get(\"tokenizer\");"], [206, ""], [207, "\t\ttry {"], [208, "\t\t\tif(tokenizer == null){"], [209, "\t\t\t\tthrow new NullPointerException();"], [210, "\t\t\t}"], [211, ""], [212, "\t\t\treturn (Splitter)tokenizer;"], [213, "\t\t} catch(RuntimeException re){"], [214, "\t\t\tthrow new IllegalArgumentException(\"The tokenizer object (\" + ClassDictUtil.formatClass(tokenizer) + \") is not Splitter\");"], [215, "\t\t}"], [216, "\t}"], [217, ""], [225, "}"]], "deleted": [[143, "\t\tString tokenPattern = getTokenPattern();"], [152, "\t\tif(stripAccents != null){"], [153, "\t\t\tthrow new IllegalArgumentException(stripAccents);"], [156, "\t\tif(tokenPattern != null && !(\"(?u)\\\\b\\\\w\\\\w+\\\\b\").equals(tokenPattern)){"], [157, "\t\t\tthrow new IllegalArgumentException(tokenPattern);"], [160, "\t\tParameterField documentField = new ParameterField(FieldName.create(\"document\"));"], [204, "}"]]}, "num_lines_added": 28, "num_lines_removed": 7}